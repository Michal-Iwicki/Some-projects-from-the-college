{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31b2496b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3bbf3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weather_to_dataframe(data: dict) -> pd.DataFrame:\n",
    "    rows = []\n",
    "\n",
    "    for day in data.get(\"days\", []):\n",
    "        for hour in day.get(\"hours\", []):\n",
    "            row = {\n",
    "                \"datetime\": hour.get(\"datetime\"),\n",
    "                \"datetimeEpoch\": hour.get(\"datetimeEpoch\"),\n",
    "                \"temp\": hour.get(\"temp\"),\n",
    "                \"feelslike\": hour.get(\"feelslike\"),\n",
    "                \"humidity\": hour.get(\"humidity\"),\n",
    "                \"dew\": hour.get(\"dew\"),\n",
    "                \"precip\": hour.get(\"precip\"),\n",
    "                \"windgust\": hour.get(\"windgust\"),\n",
    "                \"windspeed\": hour.get(\"windspeed\"),\n",
    "                \"winddir\": hour.get(\"winddir\"),\n",
    "                \"pressure\": hour.get(\"pressure\"),\n",
    "                \"cloudcover\": hour.get(\"cloudcover\"),\n",
    "                \"visibility\": hour.get(\"visibility\"),\n",
    "                \"uvindex\": hour.get(\"uvindex\"),\n",
    "                \"conditions\": hour.get(\"conditions\"),\n",
    "                \"icon\": hour.get(\"icon\"),\n",
    "                \"source\": hour.get(\"source\"),\n",
    "            }\n",
    "            rows.append(row)\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def fetch_weather(\n",
    "        start_date: str,\n",
    "        end_date: str,\n",
    "        location: str = \"KLAX\",\n",
    "        api_key: str = \"35UKBH4MZ8E34ABXX5872T7AJ\"\n",
    "        # api_key: str = \"4XQUEPUHXM742C6ZHEUSF7L5Z\"\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Fetch hourly weather data day-by-day to avoid cost overruns.\n",
    "    \"\"\"\n",
    "\n",
    "    start = datetime.fromisoformat(start_date)\n",
    "    end = datetime.fromisoformat(end_date)\n",
    "\n",
    "    all_rows = []\n",
    "\n",
    "    current = start\n",
    "    while current < end:\n",
    "        day_str = current.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        url = (\n",
    "            \"https://weather.visualcrossing.com/VisualCrossingWebServices/rest/services/\"\n",
    "            f\"timeline/{location}/{day_str}\"\n",
    "        )\n",
    "\n",
    "        params = {\n",
    "            \"unitGroup\": \"metric\",\n",
    "            \"contentType\": \"json\",\n",
    "            \"key\": api_key,\n",
    "            \"include\": \"hours\",\n",
    "        }\n",
    "\n",
    "        response = requests.get(url, params=params)\n",
    "\n",
    "        if response.status_code == 429:\n",
    "            raise RuntimeError(\n",
    "                \"Visual Crossing API quota exceeded. \"\n",
    "                \"Wait until tomorrow or reduce request volume.\"\n",
    "            )\n",
    "\n",
    "        response.raise_for_status()\n",
    "\n",
    "        data = response.json()\n",
    "\n",
    "        df_day = weather_to_dataframe(data)\n",
    "        all_rows.append(df_day)\n",
    "\n",
    "        current += timedelta(days=1)\n",
    "\n",
    "    return pd.concat(all_rows, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c41331b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_weekly_queries(\n",
    "        start_date=\"2024-09-01\",\n",
    "        end_date=\"2024-12-31\"\n",
    "):\n",
    "    start = pd.to_datetime(start_date)\n",
    "    end = pd.to_datetime(end_date)\n",
    "\n",
    "    # Weekly boundaries (7-day frequency)\n",
    "    dates = pd.date_range(start=start, end=end, freq=\"7D\")\n",
    "\n",
    "    queries = []\n",
    "    for i in range(len(dates)):\n",
    "        week_start = dates[i]\n",
    "        # Ensure the last week ends exactly at the end_date\n",
    "        if i + 1 < len(dates):\n",
    "            week_end = dates[i + 1]\n",
    "        else:\n",
    "            week_end = end + pd.Timedelta(days=1)\n",
    "\n",
    "        queries.append((\n",
    "            week_start.strftime(\"%Y-%m-%d\"),\n",
    "            week_end.strftime(\"%Y-%m-%d\")\n",
    "        ))\n",
    "\n",
    "    return queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9661d7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "NOISE_SCALES = {\n",
    "    \"temp\": 0.25,\n",
    "    \"feelslike\": 0.25,\n",
    "    \"humidity\": 1.2,\n",
    "    \"dew\": 0.2,\n",
    "    \"precip\": 0.05,\n",
    "    \"windgust\": 0.5,\n",
    "    \"windspeed\": 0.4,\n",
    "    \"winddir\": 2.8,\n",
    "    \"pressure\": 0.5,\n",
    "    \"cloudcover\": 1.9,\n",
    "    \"visibility\": 0.2,\n",
    "    \"uvindex\": 0.1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcef17b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hourly_to_minutely_weather(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    # Ensure proper datetime\n",
    "    df[\"weather_time\"] = pd.to_datetime(df[\"weather_time\"])\n",
    "\n",
    "    minute_rows = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        hour_start = row[\"weather_time\"]\n",
    "\n",
    "        # Stable seed per hour\n",
    "        seed = int(row[\"datetimeEpoch\"])\n",
    "        rng = np.random.default_rng(seed)\n",
    "\n",
    "        for minute in range(60):\n",
    "            ts = hour_start + timedelta(minutes=minute)\n",
    "            new_row = row.copy()\n",
    "            new_row[\"weather_time\"] = ts\n",
    "\n",
    "            # Smooth noise within the hour\n",
    "            phase = minute / 60\n",
    "\n",
    "            for col, scale in NOISE_SCALES.items():\n",
    "                if col not in df.columns:\n",
    "                    continue\n",
    "\n",
    "                base = row[col]\n",
    "\n",
    "                # Low-frequency intra-hour drift\n",
    "                drift = rng.normal(0, scale) * phase\n",
    "\n",
    "                # Very small white noise\n",
    "                jitter = rng.normal(0, scale * 0.1)\n",
    "\n",
    "                value = base + drift + jitter\n",
    "\n",
    "                # Physical constraints\n",
    "                if col == \"humidity\":\n",
    "                    value = np.clip(value, 0, 100)\n",
    "                elif col == \"cloudcover\":\n",
    "                    value = np.clip(value, 0, 100)\n",
    "                elif col == \"uvindex\":\n",
    "                    value = max(value, 0)\n",
    "                elif col == \"visibility\":\n",
    "                    value = max(value, 0)\n",
    "\n",
    "                new_row[col] = round(value, 2)\n",
    "\n",
    "            minute_rows.append(new_row)\n",
    "\n",
    "    minute_df = pd.DataFrame(minute_rows)\n",
    "\n",
    "    # Optional: drop original hour-only fields\n",
    "    minute_df[\"datetimeEpoch\"] = (\n",
    "        minute_df[\"weather_time\"].astype(\"int64\") // 10**9\n",
    "    )\n",
    "\n",
    "    return minute_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9679762",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hourly_to_30s_weather(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    # Ensure proper datetime\n",
    "    df[\"weather_time\"] = pd.to_datetime(df[\"weather_time\"])\n",
    "\n",
    "    rows_30s = []\n",
    "    steps_per_hour = 120\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        hour_start = row[\"weather_time\"]\n",
    "\n",
    "        # Stable seed per hour\n",
    "        seed = int(row[\"datetimeEpoch\"])\n",
    "        rng = np.random.default_rng(seed)\n",
    "\n",
    "        for step in range(steps_per_hour):\n",
    "            ts = hour_start + timedelta(seconds=30 * step)\n",
    "            new_row = row.copy()\n",
    "            new_row[\"weather_time\"] = ts\n",
    "\n",
    "            # Smooth noise within the hour\n",
    "            phase = step / steps_per_hour\n",
    "\n",
    "            for col, scale in NOISE_SCALES.items():\n",
    "                if col not in df.columns:\n",
    "                    continue\n",
    "\n",
    "                base = row[col]\n",
    "\n",
    "                # Low-frequency intra-hour drift\n",
    "                drift = rng.normal(0, scale) * phase\n",
    "\n",
    "                # Very small white noise\n",
    "                jitter = rng.normal(0, scale * 0.1)\n",
    "\n",
    "                value = base + drift + jitter\n",
    "\n",
    "                # Physical constraints\n",
    "                if col == \"humidity\":\n",
    "                    value = np.clip(value, 0, 100)\n",
    "                elif col == \"cloudcover\":\n",
    "                    value = np.clip(value, 0, 100)\n",
    "                elif col == \"uvindex\":\n",
    "                    value = max(value, 0)\n",
    "                elif col == \"visibility\":\n",
    "                    value = max(value, 0)\n",
    "\n",
    "                new_row[col] = round(value, 2)\n",
    "\n",
    "            rows_30s.append(new_row)\n",
    "\n",
    "    df_30s = pd.DataFrame(rows_30s)\n",
    "\n",
    "    # Update epoch time to match 30s resolution\n",
    "    df_30s[\"datetimeEpoch\"] = (\n",
    "        df_30s[\"weather_time\"].astype(\"int64\") // 10**9\n",
    "    )\n",
    "\n",
    "    return df_30s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f8216767",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Visual Crossing API quota exceeded. Wait until tomorrow or reduce request volume.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [23], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m     next_date \u001b[38;5;241m=\u001b[39m latest_date \u001b[38;5;241m+\u001b[39m timedelta(days\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     17\u001b[0m     end_date \u001b[38;5;241m=\u001b[39m next_date \u001b[38;5;241m+\u001b[39m timedelta(days\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 19\u001b[0m weather \u001b[38;5;241m=\u001b[39m \u001b[43mfetch_weather\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnext_date\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrftime\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mY-\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mm-\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_date\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrftime\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mY-\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mm-\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m weather[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweather_time\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(\n\u001b[0;32m     21\u001b[0m     weather[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatetimeEpoch\u001b[39m\u001b[38;5;124m\"\u001b[39m], unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     22\u001b[0m )\n\u001b[0;32m     23\u001b[0m weather[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweather_time\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m weather[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweather_time\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mtz_localize(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUTC\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mtz_convert(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAmerica/Los_Angeles\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mtz_localize(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn [18], line 64\u001b[0m, in \u001b[0;36mfetch_weather\u001b[1;34m(start_date, end_date, location, api_key)\u001b[0m\n\u001b[0;32m     61\u001b[0m response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(url, params\u001b[38;5;241m=\u001b[39mparams)\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m429\u001b[39m:\n\u001b[1;32m---> 64\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m     65\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVisual Crossing API quota exceeded. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     66\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWait until tomorrow or reduce request volume.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     67\u001b[0m     )\n\u001b[0;32m     69\u001b[0m response\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[0;32m     71\u001b[0m data \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Visual Crossing API quota exceeded. Wait until tomorrow or reduce request volume."
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    output_file=\"weather_\"\n",
    "    output_dir=\"weather\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_dir = Path(output_dir)\n",
    "    date_pattern = re.compile(rf\"{output_file}(\\d{{4}}-\\d{{2}}-\\d{{2}})\\.csv\")\n",
    "\n",
    "    existing_dates = []\n",
    "    for file in output_dir.glob(f\"{output_file}*.csv\"):\n",
    "        match = date_pattern.match(file.name)\n",
    "        if match:\n",
    "            existing_dates.append(datetime.strptime(match.group(1), \"%Y-%m-%d\").date())\n",
    "\n",
    "    if existing_dates:\n",
    "        latest_date = max(existing_dates)\n",
    "        next_date = latest_date + timedelta(days=1)\n",
    "        end_date = next_date + timedelta(days=1)\n",
    "\n",
    "    weather = fetch_weather(next_date.strftime('%Y-%m-%d'), end_date.strftime('%Y-%m-%d'))\n",
    "    weather[\"weather_time\"] = pd.to_datetime(\n",
    "        weather[\"datetimeEpoch\"], unit=\"s\"\n",
    "    )\n",
    "    weather[\"weather_time\"] = weather[\"weather_time\"].dt.tz_localize(\"UTC\").dt.tz_convert(\"America/Los_Angeles\").dt.tz_localize(None)\n",
    "    weather = weather.sort_values(\"weather_time\")\n",
    "    weather = hourly_to_30s_weather(weather)\n",
    "    weather.to_csv(f\"weather/weather_{next_date}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5eae9069",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def split_weather_by_day(input_csv, output_dir):\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    df = pd.read_csv(input_csv)\n",
    "    df[\"weather_time\"] = pd.to_datetime(df[\"weather_time\"])\n",
    "\n",
    "    # Extract date\n",
    "    df[\"date\"] = df[\"weather_time\"].dt.date\n",
    "\n",
    "    # Split and save\n",
    "    for date, day_df in df.groupby(\"date\"):\n",
    "        out_file = output_dir / f\"weather_{date}.csv\"\n",
    "        day_df.drop(columns=\"date\").to_csv(out_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7ce4d096",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_weather_by_day(\n",
    "    \"data_historic/weather_2024-10-20_to_2024-10-27.csv\",\n",
    "    \"weather\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
