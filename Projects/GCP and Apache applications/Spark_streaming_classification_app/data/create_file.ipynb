{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0061b053",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from datetime import timedelta\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c71e6749",
   "metadata": {},
   "outputs": [],
   "source": [
    "EARTHQUAKE_COLUMNS = [\n",
    "    # Properties\n",
    "    \"id\", \"mag\", \"place\", \"time\", \"updated\", \"tz\", \"url\", \"detail\",\n",
    "    \"felt\", \"cdi\", \"mmi\", \"alert\", \"status\", \"tsunami\", \"sig\",\n",
    "    \"net\", \"code\", \"ids\", \"sources\", \"types\", \"nst\", \"dmin\",\n",
    "    \"rms\", \"gap\", \"magType\", \"type\", \"title\",\n",
    "\n",
    "    # Geometry\n",
    "    \"longitude\", \"latitude\", \"depth\",\n",
    "]\n",
    "def earthquakes_to_dataframe(data: dict) -> pd.DataFrame:\n",
    "    rows = []\n",
    "\n",
    "    for feature in data.get(\"features\", []):\n",
    "        props = feature.get(\"properties\", {})\n",
    "        geom = feature.get(\"geometry\", {})\n",
    "        coords = geom.get(\"coordinates\", [None, None, None])\n",
    "\n",
    "        row = {\n",
    "            # ID\n",
    "            \"id\": feature.get(\"id\"),\n",
    "\n",
    "            # Properties\n",
    "            \"mag\": props.get(\"mag\"),\n",
    "            \"place\": props.get(\"place\"),\n",
    "            \"time\": props.get(\"time\"),\n",
    "            \"updated\": props.get(\"updated\"),\n",
    "            \"tz\": props.get(\"tz\"),\n",
    "            \"url\": props.get(\"url\"),\n",
    "            \"detail\": props.get(\"detail\"),\n",
    "            \"felt\": props.get(\"felt\"),\n",
    "            \"cdi\": props.get(\"cdi\"),\n",
    "            \"mmi\": props.get(\"mmi\"),\n",
    "            \"alert\": props.get(\"alert\"),\n",
    "            \"status\": props.get(\"status\"),\n",
    "            \"tsunami\": props.get(\"tsunami\"),\n",
    "            \"sig\": props.get(\"sig\"),\n",
    "            \"net\": props.get(\"net\"),\n",
    "            \"code\": props.get(\"code\"),\n",
    "            \"ids\": props.get(\"ids\"),\n",
    "            \"sources\": props.get(\"sources\"),\n",
    "            \"types\": props.get(\"types\"),\n",
    "            \"nst\": props.get(\"nst\"),\n",
    "            \"dmin\": props.get(\"dmin\"),\n",
    "            \"rms\": props.get(\"rms\"),\n",
    "            \"gap\": props.get(\"gap\"),\n",
    "            \"magType\": props.get(\"magType\"),\n",
    "            \"type\": props.get(\"type\"),\n",
    "            \"title\": props.get(\"title\"),\n",
    "\n",
    "            # Geometry (schema mapping)\n",
    "            \"longitude\": coords[0],\n",
    "            \"latitude\": coords[1],\n",
    "            \"depth\": coords[2],\n",
    "        }\n",
    "\n",
    "        rows.append(row)\n",
    "\n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26c21958",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_earthquakes(\n",
    "        starttime: str,\n",
    "        endtime: str,\n",
    "        latitude: float = 34.0522,\n",
    "        longitude: float = -118.2437,\n",
    "        maxradiuskm: int = 100\n",
    "):\n",
    "    \"\"\"\n",
    "    Fetch earthquake data from the USGS API.\n",
    "\n",
    "    starttime, endtime: ISO strings like '2024-09-01T00:00:00'\n",
    "    \"\"\"\n",
    "    url = \"https://earthquake.usgs.gov/fdsnws/event/1/query\"\n",
    "\n",
    "    params = {\n",
    "        \"format\": \"geojson\",\n",
    "        \"starttime\": starttime,\n",
    "        \"endtime\": endtime,\n",
    "        \"latitude\": latitude,\n",
    "        \"longitude\": longitude,\n",
    "        \"maxradiuskm\": maxradiuskm,\n",
    "        \"eventtype\": \"earthquake\",\n",
    "        \"orderby\": \"time\",\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, params=params)\n",
    "    data = response.json()\n",
    "\n",
    "    df = earthquakes_to_dataframe(data)\n",
    "    if df.empty:\n",
    "        df = pd.DataFrame(\n",
    "            [{col: None for col in EARTHQUAKE_COLUMNS}]\n",
    "        )\n",
    "        df = df.drop(columns=['url','tz','tsunami', 'detail', 'ids', 'sources', 'types'])\n",
    "        return df\n",
    "\n",
    "    \n",
    "    df['time'] = pd.to_datetime(df['time'], unit='ms')\n",
    "    df['updated'] = pd.to_datetime(df['updated'], unit='ms')\n",
    "\n",
    "    df = (\n",
    "        df\n",
    "        .sort_values('mag', ascending=False)\n",
    "        .groupby(df['time'].dt.floor('min'), as_index=False)\n",
    "        .first()\n",
    "    )\n",
    "\n",
    "    df['time'] = pd.to_datetime(df['time'], unit='ms').dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    df['updated'] = pd.to_datetime(df['updated'], unit='ms').dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    # dropping not needed columns\n",
    "\n",
    "    df = df.drop(columns=['url','tz','tsunami', 'detail', 'ids', 'sources', 'types'])\n",
    "\n",
    "    n = df['id'].notna().sum()\n",
    "    df = df.loc[:, df.notna().sum() == n]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c04b9fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_estimated_delay_backward(\n",
    "    minutes_to_departure,\n",
    "    final_delay,\n",
    "    reveal_bias,\n",
    "    noise_rng\n",
    "):\n",
    "    # No delay shown if no final delay\n",
    "    if final_delay <= 0:\n",
    "        return 0.0\n",
    "\n",
    "    # >6h out → nothing\n",
    "    if minutes_to_departure > 360:\n",
    "        return 0.0\n",
    "\n",
    "    # Progress: 6h out -> 0, departure -> 1\n",
    "    progress = 1 - (minutes_to_departure / 360)\n",
    "    progress = np.clip(progress, 0, 1)\n",
    "\n",
    "    # Small delays revealed late, big ones earlier\n",
    "    if final_delay <= 15:\n",
    "        base_power = 4.0\n",
    "    elif final_delay <= 30:\n",
    "        base_power = 2.5\n",
    "    else:\n",
    "        base_power = 1.5\n",
    "\n",
    "    reveal_power = np.clip(base_power + reveal_bias, 1.2, 5.0)\n",
    "\n",
    "    revealed_fraction = progress ** reveal_power\n",
    "    expected = final_delay * revealed_fraction\n",
    "\n",
    "    # Fading noise (cannot break constraints)\n",
    "    noise_scale = (1 - progress) * min(3, final_delay * 0.1)\n",
    "    noise = noise_rng.normal(0, noise_scale)\n",
    "\n",
    "    estimate = expected + noise\n",
    "\n",
    "    # Past planned departure → must reflect elapsed delay\n",
    "    if minutes_to_departure < 0:\n",
    "        estimate = max(estimate, abs(minutes_to_departure))\n",
    "\n",
    "    # Hard bounds\n",
    "    return float(np.clip(estimate, 0, final_delay))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff5add2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_daily_snapshots(df_flights, start_date=None):\n",
    "    flights_output_dir=\"flights\"\n",
    "    weather_output_dir=\"weather\"\n",
    "    seismic_output_dir=\"seismic\"\n",
    "    \n",
    "    os.makedirs(flights_output_dir, exist_ok=True)\n",
    "    os.makedirs(weather_output_dir, exist_ok=True)\n",
    "    os.makedirs(seismic_output_dir, exist_ok=True)\n",
    "    df = df_flights.copy()\n",
    "    df[\"Planned_DT\"] = pd.to_datetime(df[\"Planned_Dep_Timestamp\"], unit=\"s\")\n",
    "    df[\"Actual_DT\"] = pd.to_datetime(df[\"Actual_Dep_Timestamp\"], unit=\"s\", errors=\"coerce\")\n",
    "\n",
    "    while True:\n",
    "        # Date setup\n",
    "        if start_date is None:\n",
    "            now = datetime.now() - relativedelta(years=1, hours=12)\n",
    "            today = now.date()\n",
    "        else:\n",
    "            now = pd.to_datetime(start_date)\n",
    "            today = now.date()\n",
    "            start_date += relativedelta(seconds=30)\n",
    "            \n",
    "        # Flights\n",
    "\n",
    "        mask = (\n",
    "            (df[\"Planned_DT\"] < now + timedelta(hours=6)) &\n",
    "            (\n",
    "                (df[\"Actual_DT\"] > now) | \n",
    "                (df[\"Actual_DT\"].isna())\n",
    "            )\n",
    "        )\n",
    "        snapshot = df[mask].copy()\n",
    "        snapshot[\"Estimated_Delay\"] = None\n",
    "        snapshot[\"Simulation_Timestamp\"] = now.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "        for idx, row in snapshot.iterrows():\n",
    "            planned = row[\"Planned_DT\"]\n",
    "            actual = row[\"Actual_DT\"]\n",
    "\n",
    "            if pd.isna(actual) or actual > now:\n",
    "                snapshot.at[idx, \"Actual_Dep\"] = None\n",
    "                snapshot.at[idx, \"Actual_Dep_Timestamp\"] = None\n",
    "                snapshot.at[idx, \"Delay\"] = None\n",
    "                snapshot.at[idx, \"Cancelled\"] = None\n",
    "\n",
    "                minutes_to_departure = (planned - now).total_seconds() / 60\n",
    "\n",
    "                seed = abs(hash((row[\"Flight_Num\"], planned.date()))) % (2**32)\n",
    "                rng = np.random.default_rng(seed)\n",
    "\n",
    "                final_delay = row[\"Delay\"]  # ground truth\n",
    "\n",
    "                # Some flights reveal earlier / later\n",
    "                reveal_bias = rng.normal(0, 0.4)\n",
    "\n",
    "                # Stable noise across snapshots\n",
    "                noise_rng = np.random.default_rng(seed + 1)\n",
    "\n",
    "                est_delay = simulate_estimated_delay_backward(\n",
    "                    minutes_to_departure=minutes_to_departure,\n",
    "                    final_delay=final_delay,\n",
    "                    reveal_bias=reveal_bias,\n",
    "                    noise_rng=noise_rng\n",
    "                )\n",
    "\n",
    "                snapshot.at[idx, \"Estimated_Delay\"] = round(est_delay, 0)\n",
    "\n",
    "            else:\n",
    "                snapshot.at[idx, \"Estimated_Delay\"] = row[\"Delay\"]\n",
    "\n",
    "        filename = now.strftime(\"%Y-%m-%d_%H-%M-%S\") + \".csv\"\n",
    "        filepath = os.path.join(flights_output_dir, filename)\n",
    "\n",
    "        snapshot.drop(columns=[\"Planned_DT\", \"Actual_DT\"], inplace=True)\n",
    "        snapshot.to_csv(filepath, index=False)\n",
    "\n",
    "        print(f\"Saved flights: {filepath}\")\n",
    "        \n",
    "        # Weather\n",
    "        if today <= pd.to_datetime(\"2024-10-26\").date() and today >= pd.to_datetime(\"2024-09-01\").date():\n",
    "            weather_daily = pd.read_csv(f\"../data_historic/weather/weather_{today}.csv\")\n",
    "            weather_record = weather_daily[weather_daily[\"weather_time\"] == now.strftime(\"%Y-%m-%d %H:%M:%S\")]\n",
    "            \n",
    "            filename = now.strftime(\"%Y-%m-%d_%H-%M-%S\") + \".csv\"\n",
    "            filepath = os.path.join(weather_output_dir, filename)\n",
    "            weather_record.to_csv(filepath, index=False)\n",
    "            \n",
    "            print(f\"Saved weather: {filepath}\")\n",
    "            \n",
    "        # Seismic\n",
    "        starttime = now.strftime(\"%Y-%m-%dT%H:%M:%S\")\n",
    "        endtime = (now + timedelta(seconds=29)).strftime(\"%Y-%m-%dT%H:%M:%S\")\n",
    "        df_seismic = fetch_earthquakes(starttime, endtime)\n",
    "        df_seismic['time'] = pd.to_datetime(df_seismic['time']).dt.floor('min')\n",
    "        df_seismic['updated'] = pd.to_datetime(df_seismic['updated'])\n",
    "\n",
    "        start_dt = pd.to_datetime(starttime).floor('30s')\n",
    "        end_dt = pd.to_datetime(endtime).floor('30s')\n",
    "\n",
    "        full_intervals = pd.date_range(start=start_dt, end=end_dt, freq='30s')\n",
    "\n",
    "        df_seismic = df_seismic.set_index('time').reindex(full_intervals)\n",
    "\n",
    "        missing_mask = df_seismic['id'].isna()\n",
    "        df_seismic.loc[missing_mask, 'updated'] = df_seismic.index[missing_mask]\n",
    "\n",
    "        df_seismic = df_seismic.reset_index().rename(columns={'index': 'time'})\n",
    "\n",
    "        df_seismic['time'] = df_seismic['time'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        df_seismic['updated'] = pd.to_datetime(df_seismic['updated']).dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "        df_seismic['datetime'] = pd.to_datetime(df_seismic['time'])\n",
    "        filename = now.strftime(\"%Y-%m-%d_%H-%M-%S\") + \".csv\"\n",
    "        filepath = os.path.join(seismic_output_dir, filename)\n",
    "        df_seismic.to_csv(filepath, index=False)\n",
    "        print(f\"Saved seismic: {filepath}\")\n",
    "\n",
    "        time.sleep(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98f33887",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"flights_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010b9b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved flights: flights\\2024-09-04_00-41-00.csv\n",
      "Saved weather: weather\\2024-09-04_00-41-00.csv\n",
      "Saved seismic: seismic\\2024-09-04_00-41-00.csv\n",
      "Saved flights: flights\\2024-09-04_00-41-30.csv\n",
      "Saved weather: weather\\2024-09-04_00-41-30.csv\n",
      "Saved seismic: seismic\\2024-09-04_00-41-30.csv\n",
      "Saved flights: flights\\2024-09-04_00-42-00.csv\n",
      "Saved weather: weather\\2024-09-04_00-42-00.csv\n",
      "Saved seismic: seismic\\2024-09-04_00-42-00.csv\n",
      "Saved flights: flights\\2024-09-04_00-42-30.csv\n",
      "Saved weather: weather\\2024-09-04_00-42-30.csv\n",
      "Saved seismic: seismic\\2024-09-04_00-42-30.csv\n",
      "Saved flights: flights\\2024-09-04_00-43-00.csv\n",
      "Saved weather: weather\\2024-09-04_00-43-00.csv\n",
      "Saved seismic: seismic\\2024-09-04_00-43-00.csv\n"
     ]
    }
   ],
   "source": [
    "start_date = pd.to_datetime(\"2024-09-04 00:41:00\")\n",
    "save_daily_snapshots(df, start_date=start_date)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
